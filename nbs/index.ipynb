{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e53181",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from llm_rsa.core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d69ad53",
   "metadata": {},
   "source": [
    "# RSA - Recursive Self-Aggregation\n",
    "\n",
    "> A general-purpose LLM aggregation algorithm using litellm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57e4d96",
   "metadata": {},
   "source": [
    "RSA implements Recursive Self-Aggregation, a technique for improving LLM responses by generating multiple candidate answers and iteratively aggregating them. The algorithm samples k candidates from a pool of M responses, asks the LLM to synthesize an improved answer, and repeats this process across multiple loops to converge on higher-quality outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe6ff73",
   "metadata": {},
   "source": [
    "## Developer Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62448c59",
   "metadata": {},
   "source": [
    "If you are new to using `nbdev` here are some useful pointers to get you started."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae65da2c",
   "metadata": {},
   "source": [
    "### Install  in Development mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e17309",
   "metadata": {},
   "source": [
    "```sh\n",
    "# make sure  package is installed in development mode\n",
    "$ pip install -e .\n",
    "\n",
    "# make changes under nbs/ directory\n",
    "# ...\n",
    "\n",
    "# compile to have changes apply to \n",
    "$ nbdev_prepare\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0840e1b4",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0b4fca",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce78547",
   "metadata": {},
   "source": [
    "Install latest from the GitHub [repository][repo]:\n",
    "\n",
    "```sh\n",
    "$ pip install git+https://github.com//.git\n",
    "```\n",
    "\n",
    "or from [conda][conda]\n",
    "\n",
    "```sh\n",
    "$ conda install -c  \n",
    "```\n",
    "\n",
    "or from [pypi][pypi]\n",
    "\n",
    "\n",
    "```sh\n",
    "$ pip install \n",
    "```\n",
    "\n",
    "\n",
    "[repo]: \n",
    "[docs]: https://.github.io//\n",
    "[pypi]: https://pypi.org/project//\n",
    "[conda]: https://anaconda.org//"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db4df78",
   "metadata": {},
   "source": [
    "### Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e75fd3d",
   "metadata": {},
   "source": [
    "Documentation can be found hosted on this GitHub [repository][repo]'s [pages][docs]. Additionally you can find package manager specific guidelines on [conda][conda] and [pypi][pypi] respectively.\n",
    "\n",
    "[repo]: \n",
    "[docs]: https://.github.io//\n",
    "[pypi]: https://pypi.org/project//\n",
    "[conda]: https://anaconda.org//"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b077f701",
   "metadata": {},
   "source": [
    "## How to use\n",
    "\n",
    "### Basic Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a56cd9",
   "metadata": {},
   "source": [
    "Create an RSA instance with your task prompt and call it to run the aggregation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf88d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_prompt = '''Three people check into a hotel room that costs $30. They each contribute $10. \n",
    "Later, the manager realizes the room only costs $25 and gives $5 to the bellboy to return. \n",
    "The bellboy keeps $2 and gives $1 back to each person. \n",
    "So each person paid $9 (total $27), plus the bellboy has $2, which equals $29. \n",
    "Where did the extra dollar go?'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2103be",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_prompt = \"\"\"Below is a reasoning problem followed by several candidate solutions. \n",
    "Your job is to:\n",
    "1. Carefully analyze each candidate's reasoning step-by-step\n",
    "2. Identify which candidates make logical errors or arithmetic mistakes  \n",
    "3. Note which approaches lead to correct reasoning\n",
    "4. Synthesize the best reasoning into a single, clear, correct solution\n",
    "\n",
    "Show your work step-by-step, then state your final answer clearly.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e215e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "from llm_rsa.core import RSA\n",
    "\n",
    "# Create RSA instance with a reasoning task\n",
    "rsa = RSA(\n",
    "    task_prompt=task_prompt,\n",
    "    agg_prompt=agg_prompt, \n",
    "    M=4,\n",
    "    k=2,\n",
    "    loops=3\n",
    ")\n",
    "\n",
    "# Run the aggregation\n",
    "results = rsa.run()\n",
    "print(f\"Generated {len(rsa.history)} total candidates across {rsa.loops} loops\")\n",
    "print('llm response: \\n', results[-1].response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523ec080",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "from litellm import completion\n",
    "\n",
    "# Single direct call (baseline)\n",
    "response = completion(\n",
    "    model='openrouter/google/gemini-3-flash-preview',\n",
    "    messages=[{\"role\": \"user\", \"content\": task_prompt}],\n",
    "    temperature=1.0\n",
    ")\n",
    "baseline_answer = response.choices[0].message.content\n",
    "print(\"=== BASELINE (single call) ===\")\n",
    "print(baseline_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0eb852c",
   "metadata": {},
   "source": [
    "### Configuration Options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879d01b8",
   "metadata": {},
   "source": [
    "| Parameter | Default | Description |\n",
    "|-----------|---------|-------------|\n",
    "| `task_prompt` | (required) | The main task/question to solve |\n",
    "| `model` | `'openrouter/google/gemini-3-flash-preview'` | LLM model to use (any litellm-compatible model) |\n",
    "| `M` | 8 | Number of candidates generated per loop |\n",
    "| `k` | 4 | Number of candidates sampled for each aggregation |\n",
    "| `loops` | 3 | Number of aggregation iterations |\n",
    "| `temperature` | 1.0 | LLM sampling temperature |\n",
    "| `n_workers` | 4 | Parallel workers for LLM calls |\n",
    "| `agg_prompt` | (auto) | Custom aggregation prompt (optional) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fe224e",
   "metadata": {},
   "source": [
    "### How RSA Works\n",
    "\n",
    "1. **Loop 0**: Generate M independent responses to the task prompt\n",
    "2. **Loop 1+**: For each of M new candidates, randomly sample k previous candidates and ask the LLM to aggregate them into an improved answer\n",
    "3. **Repeat** for the specified number of loops\n",
    "4. **Return** the final pool of aggregated candidates\n",
    "\n",
    "The `history` attribute stores all candidates across all loops, allowing you to trace the aggregation process."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
