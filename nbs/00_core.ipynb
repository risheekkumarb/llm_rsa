{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81239f15",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "> Recursive Self-Aggregation (RSA) - A general-purpose LLM aggregation algorithm using litellm based on the paper **https://rsa-llm.github.io/**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ae2d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9678394d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd7cb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastcore.all import *\n",
    "from fastcore.test import *\n",
    "from litellm import completion\n",
    "import random, uuid\n",
    "from itertools import combinations\n",
    "from fastprogress import progress_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8def011",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RSACandidate:\n",
    "    \"A candidate response in the RSA algorithm\"\n",
    "    def __init__(self, id:str, loop_id:int, prompt:str, response:str=None, parent_ids:list=None): store_attr()\n",
    "    def __repr__(self): return f'id:{self.id}\\nloop_id:{self.loop_id}\\nprompt:\\n{self.prompt}\\nresponse:\\n{self.response}\\nparent_ids:\\n{self.parent_ids}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fd9e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id:c1\n",
       "loop_id:0\n",
       "prompt:\n",
       "Hi\n",
       "response:\n",
       "Hey\n",
       "parent_ids:\n",
       "None"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = RSACandidate(id='c1', loop_id=0, prompt='Hi')\n",
    "c.response = 'Hey'\n",
    "test_eq(c.id, 'c1')\n",
    "test_eq(c.prompt, 'Hi')\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5af69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RSA:\n",
    "    \"Recursive Self-Aggregation algorithm for LLM response aggregation\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        task_prompt:str,  # The main task/question to solve\n",
    "        agg_prompt:str=None,  # Custom aggregation prompt\n",
    "        model:str='openrouter/google/gemini-3-flash-preview',  # LLM model to use\n",
    "        N:int=4,  # Population size (candidates per loop)\n",
    "        K:int=3,  # Number of candidates to aggregate\n",
    "        loops:int=2,  # Number of aggregation loops\n",
    "        history:list=None,  # History of all candidates\n",
    "        temperature:float=1.0,  # LLM temperature\n",
    "        n_workers:int=4  # Parallel workers\n",
    "    ): \n",
    "        if not task_prompt: raise ValueError(\"task_prompt is required\")\n",
    "        store_attr()\n",
    "        if not history: self.history = L()\n",
    "        if not self.agg_prompt: self.agg_prompt = \"\"\"You are given question with training examples and a test input.\\nYou are also provided several candidate solutions. Some candidates may be incorrect\\nAggregate/consider all the candidates and use their help to produce the improved correct solution\"\"\"\n",
    "    \n",
    "    def __repr__(self): return f'RSA(model={self.model!r}, \\nN={self.N}, \\nK={self.K}, \\nloops={self.loops}, \\nhistory={len(self.history)} candidates, \\ntask_prompt={self.task_prompt})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2e65d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSA(model='openrouter/google/gemini-3-flash-preview', \n",
      "N=4, \n",
      "K=3, \n",
      "loops=2, \n",
      "history=0 candidates, \n",
      "task_prompt=A bat and ball cost $1.10 total. The bat costs $1 more than the ball. How much does the ball cost?)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "a = RSA(task_prompt='A bat and ball cost $1.10 total. The bat costs $1 more than the ball. How much does the ball cost?')\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c39e9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def _call_llm(self:RSA, prompt, **kwargs):\n",
    "    \"Call the LLM with the given prompt and return the response content\"\n",
    "    response = completion(\n",
    "        model=self.model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=self.temperature,\n",
    "        num_retries=3,\n",
    "        **kwargs\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48eb32d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The ball costs **5 cents** ($0.05).\\n\\n**Here is the algebraic breakdown:**\\n\\n1. Let $x$ be the cost of the ball.\\n2. The bat costs $1 more than the ball, so the bat is $x + $1.00.\\n3. The total cost is $1.10.\\n\\nSo, the equation is:\\n$x + (x + 1.00) = 1.10$\\n$2x + 1.00 = 1.10$\\n$2x = 0.10$\\n$x = 0.05$\\n\\n**The ball costs 5 cents and the bat costs $1.05.**'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "a._call_llm(a.task_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7144ef",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "RSA uses [litellm](https://docs.litellm.ai/) for LLM calls, which automatically reads API keys from environment variables:\n",
    "\n",
    "- `OPENAI_API_KEY` for OpenAI models\n",
    "- `ANTHROPIC_API_KEY` for Anthropic models  \n",
    "- `OPENROUTER_API_KEY` for OpenRouter models\n",
    "- etc.\n",
    "\n",
    "You can also set a custom endpoint globally:\n",
    "\n",
    "```python\n",
    "import litellm\n",
    "litellm.api_base = \"https://your-endpoint.com/v1\"\n",
    "```\n",
    "\n",
    "See [litellm's provider docs](https://docs.litellm.ai/docs/providers) for the full list of supported providers and their environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef493c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def _agg_prompt(self:RSA, candidates: list[RSACandidate]) -> str:\n",
    "    \"Build an aggregation prompt combining the task prompt with candidate responses\"\n",
    "    parts = [\n",
    "        self.agg_prompt,\n",
    "        self.task_prompt,\n",
    "        \"\\nCANDIDATE ANSWERS (may contain mistakes):\",\n",
    "    ]\n",
    "    for i, cand in enumerate(candidates, 1):\n",
    "        parts.append(f\"---- Candidate {i} ----\\n{cand.response}\")\n",
    "    parts.append(\"\\nYour response:\")\n",
    "    return \"\\n\".join(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bcdce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are given question with training examples and a test input.\n",
      "You are also provided several candidate solutions. Some candidates may be incorrect\n",
      "Aggregate/consider all the candidates and use their help to produce the improved correct solution\n",
      "A bat and ball cost $1.10 total. The bat costs $1 more than the ball. How much does the ball cost?\n",
      "\n",
      "CANDIDATE ANSWERS (may contain mistakes):\n",
      "---- Candidate 1 ----\n",
      "Answer A\n",
      "---- Candidate 2 ----\n",
      "Answer B\n",
      "\n",
      "Your response:\n"
     ]
    }
   ],
   "source": [
    "c1 = RSACandidate(id='c1', loop_id=0, prompt='test', response='Answer A')\n",
    "c2 = RSACandidate(id='c2', loop_id=0, prompt='test', response='Answer B')\n",
    "\n",
    "print(a._agg_prompt([c1, c2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81deb527",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def get_prompts(self:RSA, loop_id, cands=None):\n",
    "    \"Generate candidate prompts for a given loop: N initial candidates, or all C(n,K) combinations for aggregation\"\n",
    "    if not cands: return L(RSACandidate(id=str(uuid.uuid4()), loop_id=loop_id, prompt=self.task_prompt) for _ in range(self.N))\n",
    "    if len(cands) < self.K: raise ValueError(f\"Need at least {self.K} candidates, got {len(cands)}\")\n",
    "    sel_cands = L(combinations(cands, self.K))\n",
    "    if len(sel_cands) < self.N: raise ValueError(f\"C({len(cands)},{self.K})={len(sel_cands)} combinations is less than N={self.N}\")\n",
    "    sel_cands = sel_cands.shuffle()[:self.N]\n",
    "    return sel_cands.map(lambda x: RSACandidate(id=str(uuid.uuid4()), loop_id=loop_id, prompt=self._agg_prompt(x), parent_ids=L(x).attrgot('id')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e394854c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loop 0\n",
    "cands = a.get_prompts(loop_id=0)\n",
    "test_eq(len(cands), a.N)\n",
    "test_eq(cands[0].prompt, a.task_prompt)\n",
    "\n",
    "# Test error when candidates < k\n",
    "test_fail(lambda: a.get_prompts(loop_id=1, cands=[RSACandidate(id='x', loop_id=0, prompt='test', response='A')]), contains=\"Need at least\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9eb53eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loop 1+ (with prior candidates)\n",
    "prior = L(RSACandidate(id=str(uuid.uuid4()), loop_id=0, prompt='test', response=f'Answer {i}') for i in range(8))\n",
    "cands = a.get_prompts(loop_id=1, cands=prior)\n",
    "test_eq(len(cands), a.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f768643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are given question with training examples and a test input.\n",
      "You are also provided several candidate solutions. Some candidates may be incorrect\n",
      "Aggregate/consider all the candidates and use their help to produce the improved correct solution\n",
      "A bat and ball cost $1.10 total. The bat costs $1 more than the ball. How much does the ball cost?\n",
      "\n",
      "CANDIDATE ANSWERS (may contain mistakes):\n",
      "---- Candidate 1 ----\n",
      "Answer 0\n",
      "---- Candidate 2 ----\n",
      "Answer 1\n",
      "---- Candidate 3 ----\n",
      "Answer 7\n",
      "\n",
      "Your response:\n"
     ]
    }
   ],
   "source": [
    "print(cands[0].prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80329d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def _run_loop(self:RSA, loop_id, pool=None):\n",
    "    \"Execute one loop: generate prompts, call LLM in parallel, attach responses\"\n",
    "    prompts = self.get_prompts(loop_id, pool)\n",
    "    responses = parallel(self._call_llm, prompts.attrgot('prompt'), n_workers=self.n_workers, progress=True)\n",
    "    for p, r in zip(prompts, responses): p.response = r\n",
    "    return prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b9ae80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    progress { appearance: none; border: none; border-radius: 4px; width: 300px;\n",
       "        height: 20px; vertical-align: middle; background: #e0e0e0; }\n",
       "\n",
       "    progress::-webkit-progress-bar { background: #e0e0e0; border-radius: 4px; }\n",
       "    progress::-webkit-progress-value { background: #2196F3; border-radius: 4px; }\n",
       "    progress::-moz-progress-bar { background: #2196F3; border-radius: 4px; }\n",
       "\n",
       "    progress:not([value]) {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px); }\n",
       "\n",
       "    progress.progress-bar-interrupted::-webkit-progress-value { background: #F44336; }\n",
       "    progress.progress-bar-interrupted::-moz-progress-value { background: #F44336; }\n",
       "    progress.progress-bar-interrupted::-webkit-progress-bar { background: #F44336; }\n",
       "    progress.progress-bar-interrupted::-moz-progress-bar { background: #F44336; }\n",
       "    progress.progress-bar-interrupted { background: #F44336; }    \n",
       "\n",
       "    table.fastprogress { border-collapse: collapse; margin: 1em 0; font-size: 0.9em; }\n",
       "    table.fastprogress th, table.fastprogress td { padding: 8px 12px; border: 1px solid #ddd; text-align: left; }\n",
       "    table.fastprogress thead tr { background: #f8f9fa; font-weight: bold; }\n",
       "    table.fastprogress tbody tr:nth-of-type(even) { background: #f8f9fa; }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "did": "07a72da2366e9cd43b9575b2f553a067"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#|eval: false\n",
    "cands = a._run_loop(loop_id=0)\n",
    "test_eq(len(cands), a.N)\n",
    "assert all(c.response is not None for c in cands)\n",
    "assert cands[0].response != cands[1].response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02599e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def run(self:RSA):\n",
    "    \"Run the full RSA algorithm for the configured number of loops and return the final candidate pool\"\n",
    "    pbar = progress_bar(range(self.loops))\n",
    "    for i in pbar:\n",
    "        pbar.comment = f\"Loop {i+1}\"\n",
    "        pool = self._run_loop(i, pool if i > 0 else None)\n",
    "        self.history.extend(pool)\n",
    "    return pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd1d6e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><progress max=\"3\" value=\"3\"></progress> 100.00% [3/3 00:27&lt;00:00... Loop 3]</div>"
      ],
      "text/markdown": [
       "```html\n",
       "<div>\n",
       "<progress max=\"3\" value=\"3\"></progress> 100.00% [3/3 00:27&lt;00:00... Loop 3]</div>\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<div><progress max=\"3\" value=\"3\"></progress> 100.00% [3/3 00:27&lt;00:00... Loop 3]</div>"
      ]
     },
     "metadata": {
      "did": "2e13a90d3139f9da0d5623d512c1fe35"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "did": "90e7ff25c16b21d9025a1fffcc2514eb"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "did": "b7c735c655285b5d59aa10bb98979e9c"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "did": "cc70e1c7dde2ff898cd48ac07637772c"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final pool: 4, History: 12\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "a = RSA(task_prompt='A bat and ball cost $1.10 total. The bat costs $1 more than the ball. How much does the ball cost?', loops=2)\n",
    "result = a.run()\n",
    "print(f\"Final pool: {len(result)}, History: {len(a.history)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cb9b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def aggregate(self:RSA, agg_prompt=None, response_model=None):\n",
    "    \"Final aggregation: one LLM call to aggregate all final loop candidates, with optional structured output\"\n",
    "    agg_prompt = agg_prompt or self.agg_prompt\n",
    "    candidates = self.history.filter(lambda x: x.loop_id==(self.loops-1))\n",
    "    responses = '\\n'.join(f\"---- Candidate {i+1} ----\\n{c.response}\" for i, c in enumerate(candidates))\n",
    "    prompt = f\"{agg_prompt}\\n{self.task_prompt}\\n\\nCANDIDATE ANSWERS:\\n{responses}\\n\\nProvide the best aggregated answer:\"\n",
    "    result = self._call_llm(prompt, **({'response_format': response_model} if response_model else {}))\n",
    "    return prompt, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c318bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><progress max=\"2\" value=\"0\"></progress> 0.00% [0/2 00:00&lt;?]</div>"
      ],
      "text/markdown": [
       "```html\n",
       "<div>\n",
       "<progress max=\"2\" value=\"0\"></progress> 0.00% [0/2 00:00&lt;?]</div>\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<div><progress max=\"2\" value=\"0\"></progress> 0.00% [0/2 00:00&lt;?]</div>"
      ]
     },
     "metadata": {
      "did": "cb8185a5b5646034afcec4f215634e7d"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><progress max=\"4\" value=\"0\"></progress> 0.00% [0/4 00:00&lt;?]</div>"
      ],
      "text/markdown": [
       "```html\n",
       "<div>\n",
       "<progress max=\"4\" value=\"0\"></progress> 0.00% [0/4 00:00&lt;?]</div>\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<div><progress max=\"4\" value=\"0\"></progress> 0.00% [0/4 00:00&lt;?]</div>"
      ]
     },
     "metadata": {
      "did": "ed8e936a67172807d08f6d1afc047cb6"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#|eval: false\n",
    "# Test aggregate with custom agg_prompt\n",
    "a = RSA(task_prompt='What is 2+2?', loops=2)\n",
    "a.run()\n",
    "\n",
    "# Test with custom aggregation prompt\n",
    "custom_prompt = \"Combine these answers into one final answer:\"\n",
    "prompt, result = a.aggregate(agg_prompt=custom_prompt)\n",
    "assert custom_prompt in prompt\n",
    "assert isinstance(result, str)\n",
    "assert len(result) > 0\n",
    "\n",
    "# Test with response_model (structured output)\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Answer(BaseModel):\n",
    "    answer: str\n",
    "    confidence: float\n",
    "\n",
    "prompt, result = a.aggregate(response_model=Answer)\n",
    "assert isinstance(result, str)  # litellm returns JSON string\n",
    "print(prompt, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9e9a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
